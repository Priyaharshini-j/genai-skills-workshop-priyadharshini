{
  "cells": [
    {
      "cell_type": "code",
      "id": "ZxjFq6YxkbYUa1Rk4u0vIinP",
      "metadata": {
        "tags": [],
        "id": "ZxjFq6YxkbYUa1Rk4u0vIinP"
      },
      "source": [
        "!pip install -q google-cloud-aiplatform pytest"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required packages"
      ],
      "metadata": {
        "id": "1v3c-STNob_g"
      },
      "id": "1v3c-STNob_g"
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.language_models import ChatModel, InputOutputTextPair\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "import vertexai"
      ],
      "metadata": {
        "id": "_VnI7dVmaB_V"
      },
      "id": "_VnI7dVmaB_V",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the project"
      ],
      "metadata": {
        "id": "XrBq9y2toiHm"
      },
      "id": "XrBq9y2toiHm"
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-02-4c9c7fb5e8ec\"\n",
        "LOCATION = \"us-central1\"\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n"
      ],
      "metadata": {
        "id": "IqdR1CQnaCqZ"
      },
      "id": "IqdR1CQnaCqZ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the LLM model"
      ],
      "metadata": {
        "id": "0wDMY2Ghoi0f"
      },
      "id": "0wDMY2Ghoi0f"
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "chat_model = GenerativeModel(\"gemini-2.0-flash-001\")"
      ],
      "metadata": {
        "id": "gZ5s61fMaURL"
      },
      "id": "gZ5s61fMaURL",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python function that uses Gemini to classify the question to specific categories"
      ],
      "metadata": {
        "id": "yg8t6tNjol_g"
      },
      "id": "yg8t6tNjol_g"
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_question_category(question: str) -> str:\n",
        "    prompt = f\"\"\"You are a bot trained to categorize the any type of questions to either Employment,General Information, Emergency Services or Tax Related.\n",
        "    if the questions can't be categorized into any of this, Respond the user with \"Sorry. Your question is not be classified under Employment, General Information, Emergency Services, or Tax Related.\"\n",
        "    The classification should be only of : \"Employment\", \"General Information\", \"Emergency Services\", \"Tax Related\". or with the error prompt.\n",
        "\n",
        "    Question: {question}\"\"\"\n",
        "\n",
        "    response = chat_model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "classify_question_category(\"What is the tax on roads?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Pdd0WJyDarCU",
        "outputId": "d561bd59-bd06-4c78-b120-f1467ff9a451"
      },
      "id": "Pdd0WJyDarCU",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tax Related'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testcase for the question classification"
      ],
      "metadata": {
        "id": "XQBG-Wh_ovj6"
      },
      "id": "XQBG-Wh_ovj6"
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "class test_classification(unittest.TestCase):\n",
        "    def test_Employment(self):\n",
        "      category = classify_question_category(\"What is the current employment utilzation percentil?\")\n",
        "      self.assertEqual(category, \"Employment\")\n",
        "\n",
        "    def test_General_Information(self):\n",
        "      category = classify_question_category(\"Is the government work is more related to public?\")\n",
        "      self.assertEqual(category, \"General Information\")\n",
        "\n",
        "    def test_Emergency_Services(self):\n",
        "      category = classify_question_category(\"what is the emergency number for hospitals?\")\n",
        "      self.assertEqual(category, \"Emergency Services\")\n",
        "\n",
        "    def test_Tax_Related(self):\n",
        "      category = classify_question_category(\"what is the tax on the gold?\")\n",
        "      self.assertEqual(category, \"Tax Related\")\n",
        "\n",
        "\n",
        "unittest.main(argv=[''], verbosity=1, exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh9gpZqZbpzm",
        "outputId": "58e15077-160a-4b3e-8da7-3d1c517215a2"
      },
      "id": "yh9gpZqZbpzm",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "....\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 1.350s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7adc0bcef190>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the social post using Python function"
      ],
      "metadata": {
        "id": "afXiqfB-o1G5"
      },
      "id": "afXiqfB-o1G5"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def generate_social_post(event: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates a social media post about a government event, ensuring it's under 280 characters.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful government assistant. Write a short, friendly, informative social media post (under 280 characters) about this announcement:\n",
        "    Event: {event}\n",
        "    \"\"\"\n",
        "\n",
        "    response = chat_model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "qeLZYVqDeUWS"
      },
      "id": "qeLZYVqDeUWS",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Evaluate the Post generated by Python"
      ],
      "metadata": {
        "id": "hy-hqSzRpfHS"
      },
      "id": "hy-hqSzRpfHS"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def eval_generate_post(event: str) -> str:\n",
        "    \"\"\"\n",
        "    Evaluates a generated post based on criteria. Returns rating as a number (string).\n",
        "    \"\"\"\n",
        "    system_prompt = (\n",
        "        f\"\"\"\n",
        "        You are announcement design reviewer for a government agency.\n",
        "        You are asked to evaluate the post for public announcements based on the criteria of Clarity, Tone, Accuracy, Urgency, and Format.\n",
        "        Rate the generated post on a scale of 1 to 5 for clarity, relevance, tone, and informativeness. give the 2 hastags for the post that is generated\n",
        "        Just return the number only.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    generated_post = generate_social_post(event)\n",
        "\n",
        "    # Feed generated_post to reviewer (LLM)\n",
        "    eval_prompt = f\"{system_prompt}\\nPost: {generated_post}\"\n",
        "\n",
        "    response = chat_model.generate_content(eval_prompt)\n",
        "    return response.text.strip()"
      ],
      "metadata": {
        "id": "sqbsNKS5euVO"
      },
      "id": "sqbsNKS5euVO",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unit testcase to evaluate the post generated by the LLM"
      ],
      "metadata": {
        "id": "99wQeYCWo9kS"
      },
      "id": "99wQeYCWo9kS"
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestEvalGeneratePost(unittest.TestCase):\n",
        "\n",
        "    def test_eval_generate_post(self):\n",
        "        result = eval_generate_post(\"Say No to Single-Use Plastic!\")\n",
        "        print(result)\n",
        "\n",
        "unittest.main(argv=[''], exit=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSwuoUGxm7Tp",
        "outputId": "6111f7fb-e553-41e0-f868-2866e82da374"
      },
      "id": "QSwuoUGxm7Tp",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clarity: 5\n",
            "Tone: 5\n",
            "Accuracy: 5\n",
            "Urgency: 3\n",
            "\n",
            "#SayNoToPlastic #Sustainability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "....\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 2.409s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7adc01cc74d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-00-793a110b8712 (Jun 16, 2025, 4:31:20â€¯PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}