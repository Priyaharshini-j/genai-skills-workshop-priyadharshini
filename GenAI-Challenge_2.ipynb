{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import the required packages\n"
      ],
      "metadata": {
        "id": "0TxlebTutAGa"
      },
      "id": "0TxlebTutAGa"
    },
    {
      "cell_type": "code",
      "id": "sx02ommPStwMA4hyFnM9usj7",
      "metadata": {
        "tags": [],
        "id": "sx02ommPStwMA4hyFnM9usj7"
      },
      "source": [
        "!pip install langchain-google-genai langchain-google-vertexai langchain-google-community langchain-core --quiet\n",
        "from google.cloud import aiplatform, bigquery\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "from langchain_google_vertexai import VertexAIEmbeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the project with Env"
      ],
      "metadata": {
        "id": "_kD3SHSctDnw"
      },
      "id": "_kD3SHSctDnw"
    },
    {
      "cell_type": "code",
      "source": [
        "project = \"qwiklabs-gcp-02-4c9c7fb5e8ec\"\n",
        "location = \"US\"\n",
        "dataset = \"Aurora_dataset\"\n",
        "table_name = \"AuroraFaqs\"\n",
        "table_embed = \"Faqs_Embedded\"\n",
        "gcs_uri = \"gs://labs.roitraining.com/aurora-bay-faqs/aurora-bay-faqs.csv\""
      ],
      "metadata": {
        "id": "Re0p2aXVxEFb"
      },
      "id": "Re0p2aXVxEFb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the BigQuery Client\n"
      ],
      "metadata": {
        "id": "7X7OmCSNtJ8S"
      },
      "id": "7X7OmCSNtJ8S"
    },
    {
      "cell_type": "code",
      "source": [
        "bq_client = bigquery.Client(project=project)"
      ],
      "metadata": {
        "id": "U8Dg_g90Ecss"
      },
      "id": "U8Dg_g90Ecss",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the Dataset"
      ],
      "metadata": {
        "id": "aLgOau2JZdl_"
      },
      "id": "aLgOau2JZdl_"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset():\n",
        "    dataset_id = f\"{bq_client.project}.{dataset}\"\n",
        "    dataset_ref = bigquery.Dataset(dataset_id)\n",
        "    dataset_ref.location = location  # ✅ FIXED\n",
        "    try:\n",
        "        bq_client.create_dataset(dataset_ref, exists_ok=True)\n",
        "        print(\"✅ Dataset created.\")\n",
        "    except Exception as e:\n",
        "        print(\"✅ Dataset may already exist or error:\", e)"
      ],
      "metadata": {
        "id": "aGLPhYOKxEBr"
      },
      "id": "aGLPhYOKxEBr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data into the BigQuery"
      ],
      "metadata": {
        "id": "oskP-_WFZaCN"
      },
      "id": "oskP-_WFZaCN"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv_to_bigquery():\n",
        "  try:\n",
        "    # Create the table\n",
        "    table_id = \"{}.{}.{}\".format(bq_client.project, dataset, table_name)\n",
        "    table = bigquery.Table(table_id)\n",
        "    destination_table = bq_client.get_table(table_id)\n",
        "    table = bq_client.create_table(table)\n",
        "\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        schema=[\n",
        "        bigquery.SchemaField(\"question\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"answer\", \"STRING\"),\n",
        "        ],\n",
        "        source_format=bigquery.SourceFormat.CSV,\n",
        "        skip_leading_rows=1,\n",
        "    )\n",
        "\n",
        "    load_job = bq_client.load_table_from_uri(\n",
        "        gcs_uri, table_id, job_config=job_config\n",
        "    )\n",
        "    load_job.result()\n",
        "    print(\"✅ Data loaded into table\")\n",
        "  except Exception as e:\n",
        "    print(\"✅ Table may already exist or error:\", e)\n",
        "\n",
        "load_csv_to_bigquery()\n"
      ],
      "metadata": {
        "id": "I_lL2QUQxD56"
      },
      "id": "I_lL2QUQxD56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bq show --location=us --connection --project_id={project} \"embedding_conn\""
      ],
      "metadata": {
        "id": "DEUqrg1ZF5bf"
      },
      "id": "DEUqrg1ZF5bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establish the connection to the BigQuery Dataset we created"
      ],
      "metadata": {
        "id": "DyJXIh61tPWR"
      },
      "id": "DyJXIh61tPWR"
    },
    {
      "cell_type": "code",
      "source": [
        "connection_service_account = \"bqcx-569779670169-huh6@gcp-sa-bigquery-condel.iam.gserviceaccount.com\" # @param {\"type\": \"string\"}\n",
        "connection_member = f\"serviceAccount:{connection_service_account}\""
      ],
      "metadata": {
        "id": "EnKQ16gmxDlQ"
      },
      "id": "EnKQ16gmxDlQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the permissions for the service account"
      ],
      "metadata": {
        "id": "giL0cSULZJ5s"
      },
      "id": "giL0cSULZJ5s"
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud projects add-iam-policy-binding {project} --member='serviceAccount:bqcx-568234179561-n0wm@gcp-sa-bigquery-condel.iam.gserviceaccount.com' --role='roles/aiplatform.user' --condition=None --quiet\n"
      ],
      "metadata": {
        "id": "evUkAUSUxDgU"
      },
      "id": "evUkAUSUxDgU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Embedding model"
      ],
      "metadata": {
        "id": "OSholcPOGQN4"
      },
      "id": "OSholcPOGQN4"
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{project}.{dataset}.Embeddings`\n",
        "REMOTE WITH CONNECTION `US.embedding_conn` OPTIONS (ENDPOINT = 'text-embedding-005');\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(query)\n",
        "query_job.result()\n",
        "\n"
      ],
      "metadata": {
        "id": "iRHBqG6gxDX2"
      },
      "id": "iRHBqG6gxDX2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate embeddings"
      ],
      "metadata": {
        "id": "k8qzmrZBGWdc"
      },
      "id": "k8qzmrZBGWdc"
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{project}.{dataset}.faqs_embedded` AS SELECT *\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{project}.{dataset}.Embeddings`,\n",
        "(SELECT CONCAT(question, ' ', answer) content FROM `{project}.{dataset}.AuroraFaqs`)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "query_job = bq_client.query(query)\n",
        "query_job.result()\n"
      ],
      "metadata": {
        "id": "IPJSXJu1GR6k"
      },
      "id": "IPJSXJu1GR6k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query_insert = f\"\"\"\n",
        "INSERT INTO `{project}.{dataset}.faqs_embedded` (content, ml_generate_embedding_result)\n",
        "SELECT content, ml_generate_embedding_result\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{project}.{dataset}.Embeddings`,\n",
        "    (SELECT CONCAT(question, ' ', answer) AS content FROM `{project}.{dataset}.AuroraFaqs`)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(query_insert)\n",
        "query_job.result()"
      ],
      "metadata": {
        "id": "oMwCrVfkYPmj"
      },
      "id": "oMwCrVfkYPmj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Vector Search Results from BigQuery Table"
      ],
      "metadata": {
        "id": "l33hiZLwRPJ6"
      },
      "id": "l33hiZLwRPJ6"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = VertexAIEmbeddings(\n",
        "    model_name=\"text-embedding-005\", project=project\n",
        ")\n",
        "\n",
        "from langchain_google_community import BigQueryVectorStore\n",
        "\n",
        "store = BigQueryVectorStore(\n",
        "    project_id=project,\n",
        "    dataset_name=dataset,\n",
        "    table_name=table_embed,\n",
        "    location=location,\n",
        "    embedding=embedding,\n",
        "    embedding_field=\"ml_generate_embedding_result\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "NjrqjPdOGbQ0"
      },
      "id": "NjrqjPdOGbQ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_results(user_question):\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "      query.query,\n",
        "      result.base.question,\n",
        "      result.base.answer,\n",
        "      result.distance\n",
        "    FROM VECTOR_SEARCH(\n",
        "      TABLE `{project}.{dataset}.{table_name}`,\n",
        "      'embedding',\n",
        "      (\n",
        "        SELECT\n",
        "          ml_generate_embedding_result AS embedding,\n",
        "          '{user_question}' AS query\n",
        "        FROM ML.GENERATE_EMBEDDING(\n",
        "          MODEL `{project}.{dataset}.{table_embed}`,\n",
        "          (SELECT '{user_question}' AS content)\n",
        "        )\n",
        "      ),\n",
        "      top_k => 3,\n",
        "      options => '{{\"fraction_lists_to_search\": 1.0}}'\n",
        "    ) AS result\n",
        "    \"\"\"\n",
        "    return bq_client.query(query).to_dataframe()\n"
      ],
      "metadata": {
        "id": "8WkHILD8ROlZ"
      },
      "id": "8WkHILD8ROlZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TABLE_ID = f\"{project}.{dataset}.{table_embed}\"\n",
        "EMBED_MODEL_ID = f\"{project}.{dataset}.faqs_embedded\"\n",
        "def fetch_results(user_question):\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "      query.query,\n",
        "      result.base.question,\n",
        "      result.base.answer,\n",
        "      result.distance\n",
        "    FROM VECTOR_SEARCH(\n",
        "      TABLE `{TABLE_ID}`,\n",
        "      'embedding',\n",
        "      (\n",
        "        SELECT\n",
        "          ml_generate_embedding_result AS embedding,\n",
        "          '{user_question}' AS query\n",
        "        FROM ML.GENERATE_EMBEDDING(\n",
        "          MODEL `{EMBED_MODEL_ID}`,\n",
        "          (SELECT '{user_question}' AS content)\n",
        "        )\n",
        "      ),\n",
        "      top_k => 3,\n",
        "      options => '{{\"fraction_lists_to_search\": 1.0}}'\n",
        "    ) AS result\n",
        "    \"\"\"\n",
        "    return bq_client.query(query).to_dataframe()"
      ],
      "metadata": {
        "id": "q4qEH5idV6lC"
      },
      "id": "q4qEH5idV6lC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "chat_model = GenerativeModel(\"gemini-2.0-flash-001\")\n",
        "\n",
        "def generate_bot_response(user_input):\n",
        "    results = fetch_results(user_input)\n",
        "    context = \"\\n\\n\".join([f\"Q: {row['question']}\\nA: {row['answer']}\" for _, row in results.iterrows()])\n",
        "    prompt = f\"You are a helpful assistant for the town of Aurora Bay. Use the following FAQ context to answer:\\n\\n{context}\\n\\nUser: {user_input}\"\n",
        "    response = chat_model.generate_content(prompt)\n",
        "    return response.text\n",
        "while True:\n",
        "    question = input(\"User: \")\n",
        "    if question.strip().lower() in [\"exit\", \"no\", \"quit\"]:\n",
        "        print(\"\\nSession ended.\")\n",
        "        break\n",
        "    print(\"\\nAssistant:\", generate_bot_response(question))"
      ],
      "metadata": {
        "id": "Qfv0BeQUUhwI"
      },
      "id": "Qfv0BeQUUhwI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-00-793a110b8712 (Jun 16, 2025, 1:32:39 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}