{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Challenge 1: Gemini Prompt Security"
      ],
      "metadata": {
        "id": "XOAs1taSQp11"
      },
      "id": "XOAs1taSQp11"
    },
    {
      "cell_type": "code",
      "id": "6UiAxp1BkfsWSkF6L1AZqfwa",
      "metadata": {
        "tags": [],
        "id": "6UiAxp1BkfsWSkF6L1AZqfwa"
      },
      "source": [
        "from google.cloud import aiplatform\n",
        "from vertexai.preview.generative_models import GenerativeModel, ChatSession, HarmCategory, SafetySetting\n",
        "from google.api_core.exceptions import InvalidArgument, PermissionDenied\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the GCP Project"
      ],
      "metadata": {
        "id": "MCR5G9MgQyyB"
      },
      "id": "MCR5G9MgQyyB"
    },
    {
      "cell_type": "code",
      "source": [
        "project = \"qwiklabs-gcp-02-4c9c7fb5e8ec\"\n",
        "location = \"us-central1\"\n",
        "aiplatform.init(project=project, location=location)"
      ],
      "metadata": {
        "id": "vpwFGMnKJeNj"
      },
      "id": "vpwFGMnKJeNj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the threshold of the Safety Settings and System Instruction of the gemini"
      ],
      "metadata": {
        "id": "jO9aBY6kQ1l8"
      },
      "id": "jO9aBY6kQ1l8"
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = [\n",
        "    SafetySetting(category=HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=\"BLOCK_LOW_AND_ABOVE\"),\n",
        "    SafetySetting(category=HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=\"BLOCK_LOW_AND_ABOVE\"),\n",
        "    SafetySetting(category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=\"BLOCK_LOW_AND_ABOVE\"),\n",
        "    SafetySetting(category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=\"BLOCK_LOW_AND_ABOVE\"),\n",
        "]"
      ],
      "metadata": {
        "id": "Rnhp3NteJaKD"
      },
      "id": "Rnhp3NteJaKD",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instructions = [\"You are a bot, tasked with helping developers to assist on the data science, AI, ML, GenAI\"]"
      ],
      "metadata": {
        "id": "y8-8qsvwW8eh"
      },
      "id": "y8-8qsvwW8eh",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the Gemini Modal with the Safety Settings configured"
      ],
      "metadata": {
        "id": "0z0wiNljcu-r"
      },
      "id": "0z0wiNljcu-r"
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\n",
        "    \"gemini-2.0-flash-001\",\n",
        "    safety_settings=safety_settings,\n",
        "    system_instruction=system_instructions\n",
        ")"
      ],
      "metadata": {
        "id": "8ISZcDyDZOQx"
      },
      "id": "8ISZcDyDZOQx",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "r9rN5oOCcIiu"
      },
      "id": "r9rN5oOCcIiu",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement function to generate the response based on the user input prompt"
      ],
      "metadata": {
        "id": "ZVE5LzkxRDR7"
      },
      "id": "ZVE5LzkxRDR7"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Sends the user input to the Gemini model and returns the response.\n",
        "    If a safety setting violation occurs, returns a default message.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = chat.send_message(user_input)\n",
        "        return response.text\n",
        "    except (InvalidArgument, PermissionDenied) as e:\n",
        "        return \"Sorry, I can't answer that.\"\n"
      ],
      "metadata": {
        "id": "knSCPkvmJfYE"
      },
      "id": "knSCPkvmJfYE",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Enter your question: \")\n",
        "\n",
        "# Generate and display the response\n",
        "generate_response(user_input)"
      ],
      "metadata": {
        "id": "L-0S8iT4MzJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "1e5aea6b-fbf4-4022-e86a-b33bcb2ddf86"
      },
      "id": "L-0S8iT4MzJM",
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your question: Give one example where we can use GenAI.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, here's one example where Generative AI (GenAI) can be effectively used:\\n\\n**Example: Personalized Learning Content Creation**\\n\\n*   **Problem:** Creating personalized learning content (e.g., quizzes, explanations, exercises) for each student is time-consuming and resource-intensive for educators. Students often have different learning styles, paces, and knowledge gaps.\\n\\n*   **GenAI Solution:**\\n\\n    1.  **Student Profiling:**  Gather data about the student's past performance, learning preferences (e.g., visual, auditory, kinesthetic), and areas where they struggle.\\n    2.  **Content Generation:** Use a GenAI model (like a large language model fine-tuned for educational content) to generate:\\n        *   **Explanations:** Tailored explanations of concepts, using language and examples that resonate with the student's learning style.\\n        *   **Practice Questions:**  Create practice questions that target the student's specific weaknesses and gradually increase in difficulty.  The questions can be generated in different formats (multiple choice, short answer, coding exercises, etc.)\\n        *   **Feedback:** Generate personalized feedback on student answers, explaining why the answer was correct or incorrect and providing guidance for improvement.\\n        *   **Adaptive Learning Paths:**  Create a sequence of learning materials that adjust to the student's progress and understanding. If a student struggles with a concept, the system can automatically generate more basic content or different explanations.\\n    3.  **Content Variety:** Generate content in various formats – text, images, videos, interactive simulations – to cater to different learning preferences.\\n\\n*   **Benefits:**\\n\\n    *   **Personalized Learning:** Caters to individual student needs, leading to improved understanding and retention.\\n    *   **Increased Efficiency:** Automates content creation, freeing up educators' time for more individualized instruction and support.\\n    *   **Improved Engagement:** Makes learning more engaging and relevant for students.\\n    *   **Scalability:** Enables personalized learning at scale, making it feasible for large classes and diverse student populations.\\n    *   **Accessibility:** Content can be generated in multiple languages and adapted for students with disabilities.\\n\\n*   **GenAI Models:** Transformer-based models like GPT-3, LaMDA, or specialized educational models can be used for this purpose.  Fine-tuning these models on educational datasets would further improve their performance.\\n\\nIn summary, GenAI empowers the creation of highly personalized learning experiences, adapting content and pace to meet the unique needs of each student, ultimately leading to better learning outcomes.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-00-793a110b8712 (Jun 16, 2025, 10:36:14 AM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}